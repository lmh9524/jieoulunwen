#!/usr/bin/env python3
"""
CelebAä¼˜åŒ–è®­ç»ƒè„šæœ¬ - Stage 1
åŸºäºæµ‹è¯•é›†åˆ†æç»“æœçš„æ”¹è¿›ç‰ˆæœ¬
- é‡æ–°è®¾è®¡çš„å±æ€§åˆ†ç»„
- è°ƒæ•´çš„æŸå¤±æƒé‡
- æ—©åœæœºåˆ¶ä¸å­¦ä¹ ç‡è°ƒåº¦
- å¢å¼ºçš„æ•°æ®å¢å¼º
"""

import os
import sys
import time
import torch
import torch.nn as nn
import torch.optim as optim
from datetime import datetime
import json
import numpy as np
from torch.cuda.amp import autocast, GradScaler

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('./weak_supervised_cross_modal')

# å¯¼å…¥ä¼˜åŒ–é…ç½®å’Œæ•°æ®é›†
from config.celeba_optimized_config import get_optimized_config
from models import WeakSupervisedCrossModalAlignment
from training.losses import ComprehensiveLoss
from training.metrics import EvaluationMetrics
from data.celeba_optimized_dataset import CelebAOptimizedDatasetAdapter
from utils.logging_utils import setup_logging
from utils.checkpoint_utils import save_checkpoint, load_checkpoint, cleanup_old_checkpoints

class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    def __init__(self, patience=5, min_delta=0.001, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_loss = float('inf')
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_loss, model):
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            if self.restore_best_weights:
                self.best_weights = model.state_dict().copy()
            return False
        else:
            self.counter += 1
            return self.counter >= self.patience
    
    def restore_weights(self, model):
        if self.restore_best_weights and self.best_weights:
            model.load_state_dict(self.best_weights)

class CelebAOptimizedTrainer:
    """CelebAä¼˜åŒ–è®­ç»ƒå™¨"""
    
    def __init__(self, stage=1, data_path='D:\\KKK\\data\\CelebA'):
        """
        åˆå§‹åŒ–ä¼˜åŒ–è®­ç»ƒå™¨
        
        Args:
            stage: è®­ç»ƒé˜¶æ®µ (1, 2, 3)
            data_path: CelebAæ•°æ®é›†è·¯å¾„
        """
        # è·å–å¯¹åº”é˜¶æ®µçš„ä¼˜åŒ–é…ç½®
        self.config = get_optimized_config(stage)
        self.stage = stage
        self.config.data_path = data_path
        
        # è®¾å¤‡é…ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.config.device = self.device
        
        # å®éªŒç›®å½•
        stage_suffix = f"_stage{stage}" if stage > 1 else ""
        self.experiment_name = f"celeba_optimized_{datetime.now().strftime('%Y%m%d_%H%M%S')}{stage_suffix}"
        self.save_dir = f"./experiments/{self.experiment_name}"
        os.makedirs(self.save_dir, exist_ok=True)
        os.makedirs(f"{self.save_dir}/checkpoints", exist_ok=True)
        os.makedirs(f"{self.save_dir}/logs", exist_ok=True)
        
        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.best_val_loss = float('inf')
        self.training_history = {
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': [],
            'learning_rates': []
        }
        
        # æ—©åœå’Œè°ƒåº¦å™¨
        self.early_stopping = EarlyStopping(
            patience=self.config.early_stopping_patience,
            min_delta=0.001
        )
        
        print("=" * 70)
        print(f"CelebA ä¼˜åŒ–è®­ç»ƒå™¨åˆå§‹åŒ– - Stage {stage}")
        print("=" * 70)
        print(f"è®¾å¤‡: {self.device}")
        print(f"è®­ç»ƒè½®æ•°: {self.config.num_epochs}")
        print(f"æ‰¹å¤„ç†å¤§å°: {self.config.batch_size}")
        print(f"å­¦ä¹ ç‡: {self.config.learning_rate}")
        print(f"å®éªŒç›®å½•: {self.save_dir}")
        print(f"æ—©åœå®¹å¿: {self.config.early_stopping_patience} epochs")
        
        if self.device.type == 'cuda':
            print(f"GPU: {torch.cuda.get_device_name()}")
            print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    
    def setup_data(self):
        """è®¾ç½®ä¼˜åŒ–æ•°æ®åŠ è½½å™¨"""
        print("\nè®¾ç½®ä¼˜åŒ–æ•°æ®åŠ è½½å™¨...")
        
        adapter = CelebAOptimizedDatasetAdapter(self.config)
        self.dataloaders = adapter.get_dataloaders()
        
        # è·å–æ•°æ®é›†ä¿¡æ¯
        train_size = len(self.dataloaders['train'].dataset)
        val_size = len(self.dataloaders['val'].dataset)
        test_size = len(self.dataloaders['test'].dataset)
        
        print(f"è®­ç»ƒé›†: {train_size:,} æ ·æœ¬ (æ‰¹æ¬¡æ•°: {len(self.dataloaders['train'])})")
        print(f"éªŒè¯é›†: {val_size:,} æ ·æœ¬")
        print(f"æµ‹è¯•é›†: {test_size:,} æ ·æœ¬")
        
        return True
    
    def setup_model(self):
        """è®¾ç½®ä¼˜åŒ–æ¨¡å‹"""
        print("\nè®¾ç½®ä¼˜åŒ–æ¨¡å‹...")
        
        # åˆ›å»ºæ¨¡å‹
        self.model = WeakSupervisedCrossModalAlignment(self.config)
        self.model.to(self.device)
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        print(f"æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
        print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        # æ‰“å°å¯ç”¨çš„æ¨¡å—
        enabled_modules = []
        if self.config.use_frequency_decoupling:
            enabled_modules.append("AFANet")
        if self.config.use_hierarchical_decomposition:
            enabled_modules.append("WINNER") 
        if self.config.use_dynamic_routing:
            enabled_modules.append("MAVD")
        if self.config.use_cmdl_regularization:
            enabled_modules.append("CMDL")
        
        print(f"å¯ç”¨æ¨¡å—: {enabled_modules if enabled_modules else ['ä»…åŸºç¡€åˆ†ç±»']}")
        
        # åˆ›å»ºæŸå¤±å‡½æ•°
        self.criterion = ComprehensiveLoss(self.config)
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay,
            eps=1e-8
        )
        
        # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=self.config.lr_reduce_factor,
            patience=self.config.lr_reduce_patience,
            verbose=True,
            min_lr=1e-7
        )
        
        # AMPæ··åˆç²¾åº¦
        self.scaler = GradScaler(enabled=(self.device.type == 'cuda'))
        
        # OOMä¿æŠ¤æœºåˆ¶
        self.original_batch_size = self.config.batch_size
        self.oom_count = 0
        
        # è¯„ä¼°æŒ‡æ ‡
        self.metrics = EvaluationMetrics(self.config.num_classes)
        
        return True
    
    def _handle_oom(self):
        """å¤„ç†OOMå¼‚å¸¸"""
        self.oom_count += 1
        print(f"âš ï¸ GPUå†…å­˜ä¸è¶³! ç¬¬{self.oom_count}æ¬¡OOM")
        
        if self.oom_count <= 3:
            # æ¸…ç†ç¼“å­˜
            torch.cuda.empty_cache()
            
            # å‡å°‘batch_size
            new_batch_size = max(4, self.config.batch_size // 2)
            if new_batch_size != self.config.batch_size:
                print(f"ğŸ”§ è‡ªåŠ¨è°ƒæ•´batch_size: {self.config.batch_size} â†’ {new_batch_size}")
                self.config.batch_size = new_batch_size
                
                # é‡æ–°åˆ›å»ºæ•°æ®åŠ è½½å™¨
                print("ğŸ”„ é‡æ–°åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
                self.setup_data()
        else:
            print("âŒ å¤šæ¬¡OOMï¼Œå»ºè®®æ£€æŸ¥GPUå†…å­˜æˆ–é™ä½æ¨¡å‹å¤æ‚åº¦")
            raise RuntimeError("è¿ç»­OOMè¶…è¿‡3æ¬¡ï¼Œè®­ç»ƒç»ˆæ­¢")
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        total_loss = 0.0
        total_samples = 0
        correct_predictions = {}
        total_predictions = {}
        
        # åˆå§‹åŒ–å‡†ç¡®ç‡ç»Ÿè®¡
        for key in self.config.num_classes.keys():
            correct_predictions[key] = 0
            total_predictions[key] = 0
        
        print(f"\nEpoch {epoch+1}/{self.config.num_epochs} - è®­ç»ƒé˜¶æ®µ")
        
        start_time = time.time()
        for batch_idx, (images, targets) in enumerate(self.dataloaders['train']):
            # æ•°æ®ç§»åˆ°è®¾å¤‡
            images = images.to(self.device)
            targets = {k: v.to(self.device) for k, v in targets.items()}
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad(set_to_none=True)
            
            with autocast(enabled=(self.device.type == 'cuda')):
                outputs = self.model(images)
                # è®¡ç®—æŸå¤±
                loss, loss_components = self.criterion(outputs, targets, epoch)
            
            # åå‘ä¼ æ’­ with AMP
            try:
                self.scaler.scale(loss).backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                self.scaler.step(self.optimizer)
                self.scaler.update()
            except RuntimeError as e:
                if "out of memory" in str(e).lower():
                    self._handle_oom()
                    continue
                else:
                    raise e
            
            # ç»Ÿè®¡
            batch_size = images.size(0)
            total_loss += loss.item() * batch_size
            total_samples += batch_size
            
            # è®¡ç®—å‡†ç¡®ç‡
            for key in self.config.num_classes.keys():
                if 'predictions' in outputs and key in outputs['predictions'] and key in targets:
                    logits = outputs['predictions'][key]
                    pred = torch.argmax(logits, dim=1)
                    correct = (pred == targets[key]).sum().item()
                    correct_predictions[key] += correct
                    total_predictions[key] += batch_size
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 50 == 0:
                progress = 100. * batch_idx / len(self.dataloaders['train'])
                elapsed = time.time() - start_time
                eta = elapsed / max(1, batch_idx + 1) * (len(self.dataloaders['train']) - batch_idx - 1)
                print(f"  è¿›åº¦: {progress:.1f}%, æŸå¤±: {loss.item():.4f}, ETA: {eta/60:.1f}min")
        
        # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
        avg_loss = total_loss / total_samples
        avg_accuracy = {}
        for key in self.config.num_classes.keys():
            if total_predictions[key] > 0:
                avg_accuracy[key] = correct_predictions[key] / total_predictions[key]
        
        overall_accuracy = np.mean(list(avg_accuracy.values()))
        
        print(f"  è®­ç»ƒæŸå¤±: {avg_loss:.4f}")
        print(f"  è®­ç»ƒå‡†ç¡®ç‡: {overall_accuracy:.4f}")
        print(f"  å½“å‰å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.2e}")
        
        return avg_loss, overall_accuracy
    
    def validate_epoch(self, epoch):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        
        total_loss = 0.0
        total_samples = 0
        self.metrics.reset()
        
        print(f"  éªŒè¯é˜¶æ®µ...")
        
        with torch.no_grad():
            for images, targets in self.dataloaders['val']:
                # æ•°æ®ç§»åˆ°è®¾å¤‡
                images = images.to(self.device)
                targets = {k: v.to(self.device) for k, v in targets.items()}
                
                # å‰å‘ä¼ æ’­
                with autocast(enabled=(self.device.type == 'cuda')):
                    outputs = self.model(images)
                    # è®¡ç®—æŸå¤±
                    loss, _ = self.criterion(outputs, targets, epoch)
                
                # ç»Ÿè®¡
                batch_size = images.size(0)
                total_loss += loss.item() * batch_size
                total_samples += batch_size
                
                # æ›´æ–°è¯„ä¼°æŒ‡æ ‡
                if 'predictions' in outputs:
                    self.metrics.update(outputs['predictions'], targets)
        
        # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
        avg_loss = total_loss / total_samples
        metric_results = self.metrics.compute()
        overall_accuracy = metric_results.get('mean_accuracy', 0.0)
        
        print(f"  éªŒè¯æŸå¤±: {avg_loss:.4f}")
        print(f"  éªŒè¯å‡†ç¡®ç‡: {overall_accuracy:.4f}")
        
        # æ‰“å°å„å±æ€§ç»„æ€§èƒ½
        print("  å„å±æ€§ç»„éªŒè¯å‡†ç¡®ç‡:")
        for attr in self.config.num_classes.keys():
            acc = metric_results.get(f'{attr}_accuracy', 0.0)
            print(f"    {attr}: {acc:.4f}")
        
        return avg_loss, overall_accuracy, metric_results
    
    def save_checkpoint(self, epoch, is_best=False, metric_results=None):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'training_history': self.training_history,
            'config': self.config,
            'stage': self.stage,
            'metric_results': metric_results
        }
        
        # ä¿å­˜å½“å‰æ£€æŸ¥ç‚¹
        checkpoint_path = f"{self.save_dir}/checkpoints/checkpoint_epoch_{epoch}.pth"
        torch.save(checkpoint, checkpoint_path)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = f"{self.save_dir}/checkpoints/best_model.pth"
            torch.save(checkpoint, best_path)
            print(f"  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: best_model.pth")
        
        # è‡ªåŠ¨æ¸…ç†æ—§æ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™æœ€è¿‘3ä¸ª
        try:
            cleanup_old_checkpoints(f"{self.save_dir}/checkpoints", keep_count=3)
        except Exception as e:
            print(f"  âš ï¸ æ¸…ç†æ—§æ£€æŸ¥ç‚¹æ—¶å‡ºé”™: {e}")
    
    def train(self):
        """æ‰§è¡Œå®Œæ•´ä¼˜åŒ–è®­ç»ƒæµç¨‹"""
        print(f"\nå¼€å§‹CelebAä¼˜åŒ–è®­ç»ƒ - Stage {self.stage}...")
        
        # è®¾ç½®æ•°æ®å’Œæ¨¡å‹
        if not self.setup_data():
            return False
        
        if not self.setup_model():
            return False
        
        # ä¿å­˜é…ç½®
        config_path = f"{self.save_dir}/config.json"
        with open(config_path, 'w') as f:
            config_dict = {
                'stage': self.stage,
                'dataset_name': self.config.dataset_name,
                'num_epochs': self.config.num_epochs,
                'batch_size': self.config.batch_size,
                'learning_rate': self.config.learning_rate,
                'image_size': self.config.image_size,
                'num_classes': self.config.num_classes,
                'loss_weights': self.config.loss_weights,
                'early_stopping_patience': self.config.early_stopping_patience,
                'enabled_modules': {
                    'frequency_decoupling': self.config.use_frequency_decoupling,
                    'hierarchical_decomposition': self.config.use_hierarchical_decomposition,
                    'dynamic_routing': self.config.use_dynamic_routing,
                    'cmdl_regularization': self.config.use_cmdl_regularization
                }
            }
            json.dump(config_dict, f, indent=2)
        
        # è®­ç»ƒå¾ªç¯
        start_time = time.time()
        
        print(f"ğŸš€ å¼€å§‹Stage {self.stage}è®­ç»ƒ: 0 -> {self.config.num_epochs-1} epochs")
        
        for epoch in range(self.config.num_epochs):
            print(f"\n{'='*70}")
            print(f"Epoch {epoch+1}/{self.config.num_epochs} - Stage {self.stage}")
            print(f"{'='*70}")
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(epoch)
            
            # éªŒè¯
            val_loss, val_acc, metric_results = self.validate_epoch(epoch)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step(val_loss)
            current_lr = self.optimizer.param_groups[0]['lr']
            
            # è®°å½•å†å²
            self.training_history['train_loss'].append(train_loss)
            self.training_history['val_loss'].append(val_loss)
            self.training_history['train_acc'].append(train_acc)
            self.training_history['val_acc'].append(val_acc)
            self.training_history['learning_rates'].append(current_lr)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
            is_best = val_loss < self.best_val_loss
            if is_best:
                self.best_val_loss = val_loss
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            self.save_checkpoint(epoch, is_best, metric_results)
            
            # æ—©åœæ£€æŸ¥
            if self.early_stopping(val_loss, self.model):
                print(f"\nğŸ›‘ æ—©åœè§¦å‘ï¼åœ¨ Epoch {epoch+1} åœæ­¢è®­ç»ƒ")
                print(f"æœ€ä½³éªŒè¯æŸå¤±: {self.early_stopping.best_loss:.4f}")
                if self.early_stopping.restore_best_weights:
                    self.early_stopping.restore_weights(self.model)
                    print("å·²æ¢å¤æœ€ä½³æƒé‡")
                break
            
            # æ‰“å°æ‘˜è¦
            elapsed = time.time() - start_time
            print(f"\nğŸ“Š Epoch {epoch+1} æ‘˜è¦:")
            print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}")
            print(f"  éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
            print(f"  æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.4f}")
            print(f"  å­¦ä¹ ç‡: {current_lr:.2e}")
            print(f"  ç´¯è®¡ç”¨æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
            print(f"  æ—©åœè®¡æ•°: {self.early_stopping.counter}/{self.early_stopping.patience}")
        
        # è®­ç»ƒå®Œæˆ
        total_time = time.time() - start_time
        self.generate_training_report(total_time)
        
        return True
    
    def generate_training_report(self, total_time):
        """ç”Ÿæˆä¼˜åŒ–è®­ç»ƒæŠ¥å‘Š"""
        print("\n" + "="*70)
        print(f"CelebA Stage {self.stage} ä¼˜åŒ–è®­ç»ƒå®ŒæˆæŠ¥å‘Š")
        print("="*70)
        
        print(f"æ€»è®­ç»ƒæ—¶é—´: {total_time/3600:.2f} å°æ—¶")
        print(f"æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.4f}")
        print(f"æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {self.training_history['train_acc'][-1]:.4f}")
        print(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {self.training_history['val_acc'][-1]:.4f}")
        print(f"æœ€ç»ˆå­¦ä¹ ç‡: {self.training_history['learning_rates'][-1]:.2e}")
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = f"{self.save_dir}/training_history.json"
        with open(history_path, 'w') as f:
            json.dump(self.training_history, f, indent=2)
        
        # ä¿å­˜è®­ç»ƒæŠ¥å‘Š
        report = {
            "experiment_name": self.experiment_name,
            "stage": self.stage,
            "dataset": self.config.dataset_name,
            "total_epochs": len(self.training_history['train_loss']),
            "planned_epochs": self.config.num_epochs,
            "total_time_hours": total_time / 3600,
            "best_val_loss": self.best_val_loss,
            "final_train_acc": self.training_history['train_acc'][-1],
            "final_val_acc": self.training_history['val_acc'][-1],
            "final_lr": self.training_history['learning_rates'][-1],
            "model_parameters": sum(p.numel() for p in self.model.parameters()),
            "device": str(self.device),
            "early_stopped": len(self.training_history['train_loss']) < self.config.num_epochs,
            "config": {
                "batch_size": self.config.batch_size,
                "learning_rate": self.config.learning_rate,
                "num_classes": self.config.num_classes,
                "loss_weights": self.config.loss_weights
            }
        }
        
        report_path = f"{self.save_dir}/training_report.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"\nğŸ“„ è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        print(f"ğŸ“„ è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")
        print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {self.save_dir}/checkpoints/best_model.pth")
        print("="*70)

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='CelebAä¼˜åŒ–è®­ç»ƒ')
    parser.add_argument('--stage', type=int, default=1, choices=[1, 2, 3], 
                       help='è®­ç»ƒé˜¶æ®µ (1: åŸºç¡€ä¼˜åŒ–, 2: +è½»é‡æ¨¡å—, 3: +å®Œæ•´æ¨¡å—)')
    parser.add_argument('--data-path', type=str, default='D:\\KKK\\data\\CelebA',
                       help='CelebAæ•°æ®é›†è·¯å¾„')
    
    args = parser.parse_args()
    
    print("CelebA ä¼˜åŒ–è®­ç»ƒå¯åŠ¨")
    print("Copyright (c) 2024 - å¼±ç›‘ç£è§£è€¦çš„è·¨æ¨¡æ€å±æ€§å¯¹é½é¡¹ç›®")
    
    # æ£€æŸ¥æ•°æ®é›†
    if not os.path.exists(args.data_path):
        print(f"âŒ é”™è¯¯: CelebAæ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {args.data_path}")
        return
    
    print(f"âœ… CelebAæ•°æ®é›†æ£€æŸ¥é€šè¿‡: {args.data_path}")
    
    # åˆ›å»ºä¼˜åŒ–è®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = CelebAOptimizedTrainer(
        stage=args.stage,
        data_path=args.data_path
    )
    
    success = trainer.train()
    
    if success:
        print(f"\nğŸ‰ CelebA Stage {args.stage} ä¼˜åŒ–è®­ç»ƒæˆåŠŸå®Œæˆ!")
    else:
        print(f"\nâŒ CelebA Stage {args.stage} ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")

if __name__ == "__main__":
    main() 