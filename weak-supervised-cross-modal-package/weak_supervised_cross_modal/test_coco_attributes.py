"""
æµ‹è¯•COCOAttributesæ•°æ®é›†åŠ è½½å™¨
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import torch
from config.base_config import get_config
from data.dataset_adapters import COCOAttributesDatasetAdapter

def test_coco_attributes_dataset():
    """æµ‹è¯•COCOAttributesæ•°æ®é›†åŠ è½½"""
    print("å¼€å§‹æµ‹è¯•COCOAttributesæ•°æ®é›†åŠ è½½å™¨...")
    
    # è·å–é…ç½®
    config = get_config('COCOAttributes')
    print(f"æ•°æ®è·¯å¾„: {config.data_path}")
    print(f"å›¾åƒå¤§å°: {config.image_size}")
    print(f"å±æ€§æ•°é‡: {config.num_attributes}")
    print(f"å±æ€§ç±»åˆ«: {config.num_classes}")
    
    # åˆ›å»ºæ•°æ®é€‚é…å™¨
    try:
        adapter = COCOAttributesDatasetAdapter(config)
        print("âœ… COCOAttributesæ•°æ®é€‚é…å™¨åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ COCOAttributesæ•°æ®é€‚é…å™¨åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    try:
        dataloaders = adapter.get_dataloaders()
        print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥æ•°æ®åŠ è½½å™¨
        for split, dataloader in dataloaders.items():
            print(f"  {split}: {len(dataloader.dataset)} ä¸ªæ ·æœ¬")
            
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æµ‹è¯•åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®
    try:
        train_loader = dataloaders['train']
        print(f"\næµ‹è¯•æ•°æ®åŠ è½½ (æ‰¹æ¬¡å¤§å°: {train_loader.batch_size})...")
        
        for batch_idx, (images, targets) in enumerate(train_loader):
            print(f"âœ… æˆåŠŸåŠ è½½ç¬¬ {batch_idx + 1} ä¸ªæ‰¹æ¬¡:")
            print(f"  å›¾åƒå½¢çŠ¶: {images.shape}")
            print(f"  å›¾åƒæ•°æ®ç±»å‹: {images.dtype}")
            print(f"  å›¾åƒå€¼èŒƒå›´: [{images.min():.3f}, {images.max():.3f}]")
            
            print(f"  ç›®æ ‡é”®: {list(targets.keys())}")
            for key, value in targets.items():
                if isinstance(value, torch.Tensor):
                    print(f"    {key}: å½¢çŠ¶={value.shape}, ç±»å‹={value.dtype}, èŒƒå›´=[{value.min()}, {value.max()}]")
                else:
                    print(f"    {key}: {type(value)}")
            
            # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
            break
            
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æµ‹è¯•éªŒè¯é›†
    try:
        val_loader = dataloaders['val']
        print(f"\næµ‹è¯•éªŒè¯é›†æ•°æ®åŠ è½½...")
        
        for batch_idx, (images, targets) in enumerate(val_loader):
            print(f"âœ… éªŒè¯é›†æ‰¹æ¬¡ {batch_idx + 1}:")
            print(f"  å›¾åƒå½¢çŠ¶: {images.shape}")
            print(f"  ç›®æ ‡æ•°é‡: {len(targets)}")
            break
            
    except Exception as e:
        print(f"âŒ éªŒè¯é›†æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("âœ… COCOAttributesæ•°æ®é›†æµ‹è¯•å®Œæˆ!")
    return True

def test_model_compatibility():
    """æµ‹è¯•æ¨¡å‹å…¼å®¹æ€§"""
    print("\nå¼€å§‹æµ‹è¯•æ¨¡å‹å…¼å®¹æ€§...")
    
    try:
        # è·å–é…ç½®
        config = get_config('COCOAttributes')
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        adapter = COCOAttributesDatasetAdapter(config)
        dataloaders = adapter.get_dataloaders()
        
        # å¯¼å…¥æ¨¡å‹
        from models import WeakSupervisedCrossModalAlignment
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = WeakSupervisedCrossModalAlignment(config).to(device)
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œè®¾å¤‡: {device}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        train_loader = dataloaders['train']
        for images, targets in train_loader:
            images = images.to(device)
            targets = {k: v.to(device) for k, v in targets.items()}
            
            # å‰å‘ä¼ æ’­
            with torch.no_grad():
                outputs = model(images)
            
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ:")
            print(f"  è¾“å…¥å½¢çŠ¶: {images.shape}")
            print(f"  è¾“å‡ºé”®: {list(outputs.keys())}")
            
            for key, value in outputs.items():
                if isinstance(value, dict):
                    print(f"    {key}: {list(value.keys())}")
                    for sub_key, sub_value in value.items():
                        if isinstance(sub_value, torch.Tensor):
                            print(f"      {sub_key}: {sub_value.shape}")
                elif isinstance(value, torch.Tensor):
                    print(f"    {key}: {value.shape}")
            
            break
        
        print("âœ… æ¨¡å‹å…¼å®¹æ€§æµ‹è¯•å®Œæˆ!")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_loss_computation():
    """æµ‹è¯•æŸå¤±è®¡ç®—"""
    print("\nå¼€å§‹æµ‹è¯•æŸå¤±è®¡ç®—...")
    
    try:
        # è·å–é…ç½®
        config = get_config('COCOAttributes')
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        adapter = COCOAttributesDatasetAdapter(config)
        dataloaders = adapter.get_dataloaders()
        
        # åˆ›å»ºæ¨¡å‹å’ŒæŸå¤±å‡½æ•°
        from models import WeakSupervisedCrossModalAlignment
        from training.losses import ComprehensiveLoss
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = WeakSupervisedCrossModalAlignment(config).to(device)
        criterion = ComprehensiveLoss(config)
        
        print("âœ… æ¨¡å‹å’ŒæŸå¤±å‡½æ•°åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æŸå¤±è®¡ç®—
        train_loader = dataloaders['train']
        for images, targets in train_loader:
            images = images.to(device)
            targets = {k: v.to(device) for k, v in targets.items()}
            
            # å‰å‘ä¼ æ’­
            outputs = model(images)
            
            # è®¡ç®—æŸå¤±
            total_loss, loss_dict = criterion(outputs, targets, epoch=0)
            
            print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸ:")
            print(f"  æ€»æŸå¤±: {total_loss.item():.4f}")
            print(f"  æŸå¤±ç»„ä»¶:")
            for key, value in loss_dict.items():
                if isinstance(value, torch.Tensor):
                    print(f"    {key}: {value.item():.4f}")
                else:
                    print(f"    {key}: {value}")
            
            break
        
        print("âœ… æŸå¤±è®¡ç®—æµ‹è¯•å®Œæˆ!")
        return True
        
    except Exception as e:
        print(f"âŒ æŸå¤±è®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹COCOAttributeså®Œæ•´æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•1: æ•°æ®é›†åŠ è½½
    success1 = test_coco_attributes_dataset()
    
    # æµ‹è¯•2: æ¨¡å‹å…¼å®¹æ€§
    success2 = test_model_compatibility()
    
    # æµ‹è¯•3: æŸå¤±è®¡ç®—
    success3 = test_loss_computation()
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print(f"  æ•°æ®é›†åŠ è½½: {'âœ… æˆåŠŸ' if success1 else 'âŒ å¤±è´¥'}")
    print(f"  æ¨¡å‹å…¼å®¹æ€§: {'âœ… æˆåŠŸ' if success2 else 'âŒ å¤±è´¥'}")
    print(f"  æŸå¤±è®¡ç®—: {'âœ… æˆåŠŸ' if success3 else 'âŒ å¤±è´¥'}")
    
    if success1 and success2 and success3:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! COCOAttributesæ•°æ®é›†å·²å‡†å¤‡å°±ç»ª!")
        print("\nä¸‹ä¸€æ­¥å¯ä»¥è¿è¡Œ:")
        print("  python train_coco_attributes.py --epochs 5")
        return True
    else:
        print("\nğŸ’¥ éƒ¨åˆ†æµ‹è¯•å¤±è´¥! éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•!")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ† COCOAttributesæµ‹è¯•å®Œæˆ!")
    else:
        print("\nğŸ”§ COCOAttributeséœ€è¦è¿›ä¸€æ­¥è°ƒè¯•!")
