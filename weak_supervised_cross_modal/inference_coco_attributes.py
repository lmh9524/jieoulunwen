"""
COCOAttributesæ•°æ®é›†æ¨ç†è„šæœ¬
"""
import sys
import os
import torch
import torch.nn.functional as F
from PIL import Image
import torchvision.transforms as transforms
import argparse
import json
import numpy as np
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def load_model(model_path, config, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    from models import WeakSupervisedCrossModalAlignment
    
    model = WeakSupervisedCrossModalAlignment(config)
    
    if os.path.exists(model_path):
        print(f"åŠ è½½æ¨¡å‹: {model_path}")
        checkpoint = torch.load(model_path, map_location=device)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"æ¨¡å‹è®­ç»ƒepoch: {checkpoint.get('epoch', 'unknown')}")
            print(f"éªŒè¯æŸå¤±: {checkpoint.get('val_loss', 'unknown')}")
        else:
            model.load_state_dict(checkpoint)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    else:
        print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹: {model_path}")
    
    model.to(device)
    model.eval()
    return model

def preprocess_image(image_path, image_size=224):
    """é¢„å¤„ç†å•å¼ å›¾åƒ"""
    transform = transforms.Compose([
        transforms.Resize((image_size, image_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0)  # æ·»åŠ batchç»´åº¦
    
    return image_tensor

def predict_attributes(model, image_tensor, config, device):
    """å¯¹å•å¼ å›¾åƒè¿›è¡Œå±æ€§é¢„æµ‹"""
    model.eval()
    image_tensor = image_tensor.to(device)
    
    with torch.no_grad():
        outputs = model(image_tensor)
        predictions = outputs['predictions']
        
        # å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡å’Œé¢„æµ‹ç±»åˆ«
        results = {}
        for attr_name, logits in predictions.items():
            if attr_name in config.num_classes:
                probs = F.softmax(logits, dim=-1)
                pred_class = torch.argmax(probs, dim=-1)
                confidence = torch.max(probs, dim=-1)[0]
                
                results[attr_name] = {
                    'predicted_class': pred_class.cpu().item(),
                    'confidence': confidence.cpu().item(),
                    'probabilities': probs.cpu().numpy().tolist()[0]
                }
    
    return results

def get_attribute_class_names():
    """è·å–å±æ€§ç±»åˆ«åç§°æ˜ å°„"""
    class_names = {}
    
    # é¢œè‰²å±æ€§
    class_names['color'] = [
        'red', 'blue', 'green', 'yellow', 'orange', 'purple', 
        'pink', 'brown', 'black', 'white', 'gray', 'multicolor'
    ]
    
    # æè´¨å±æ€§
    class_names['material'] = [
        'metal', 'wood', 'plastic', 'fabric', 'glass', 'ceramic',
        'leather', 'rubber', 'stone', 'paper', 'fur', 'feather',
        'liquid', 'transparent', 'reflective'
    ]
    
    # å½¢çŠ¶å±æ€§
    class_names['shape'] = [
        'round', 'square', 'rectangular', 'triangular', 'oval', 'cylindrical',
        'spherical', 'flat', 'curved', 'straight', 'pointed', 'blunt',
        'thin', 'thick', 'long', 'short', 'wide', 'narrow', 'large', 'small'
    ]
    
    # çº¹ç†å±æ€§
    class_names['texture'] = [
        'smooth', 'rough', 'bumpy', 'striped', 'spotted', 
        'patterned', 'plain', 'textured', 'shiny', 'matte'
    ]
    
    # å¤§å°å±æ€§
    class_names['size'] = [
        'tiny', 'small', 'medium', 'large', 'huge'
    ]
    
    # å…¶ä»–å±æ€§
    class_names['other'] = [
        'natural', 'artificial', 'old', 'new', 'clean', 'dirty', 'broken', 'intact'
    ]
    
    return class_names

def format_results(results, class_names):
    """æ ¼å¼åŒ–é¢„æµ‹ç»“æœ"""
    formatted = {}
    
    for attr_name, pred_info in results.items():
        if attr_name in class_names:
            pred_class_idx = pred_info['predicted_class']
            confidence = pred_info['confidence']
            
            if pred_class_idx < len(class_names[attr_name]):
                class_name = class_names[attr_name][pred_class_idx]
            else:
                class_name = f"class_{pred_class_idx}"
            
            formatted[attr_name] = {
                'predicted_class': class_name,
                'confidence': f"{confidence:.4f}",
                'class_index': pred_class_idx
            }
    
    return formatted

def batch_inference(model, image_paths, config, device, batch_size=8):
    """æ‰¹é‡æ¨ç†"""
    results = []
    
    # é¢„å¤„ç†æ‰€æœ‰å›¾åƒ
    images = []
    valid_paths = []
    
    for img_path in image_paths:
        try:
            img_tensor = preprocess_image(img_path, config.image_size)
            images.append(img_tensor)
            valid_paths.append(img_path)
        except Exception as e:
            print(f"è·³è¿‡æ— æ•ˆå›¾åƒ {img_path}: {e}")
    
    if not images:
        return []
    
    # æ‰¹é‡å¤„ç†
    for i in range(0, len(images), batch_size):
        batch_images = images[i:i+batch_size]
        batch_paths = valid_paths[i:i+batch_size]
        
        # åˆå¹¶ä¸ºæ‰¹æ¬¡
        batch_tensor = torch.cat(batch_images, dim=0).to(device)
        
        with torch.no_grad():
            outputs = model(batch_tensor)
            predictions = outputs['predictions']
            
            # å¤„ç†æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬
            for j in range(batch_tensor.size(0)):
                sample_results = {}
                for attr_name, logits in predictions.items():
                    if attr_name in config.num_classes:
                        probs = F.softmax(logits[j:j+1], dim=-1)
                        pred_class = torch.argmax(probs, dim=-1)
                        confidence = torch.max(probs, dim=-1)[0]
                        
                        sample_results[attr_name] = {
                            'predicted_class': pred_class.cpu().item(),
                            'confidence': confidence.cpu().item(),
                            'probabilities': probs.cpu().numpy().tolist()[0]
                        }
                
                results.append({
                    'image_path': batch_paths[j],
                    'predictions': sample_results
                })
    
    return results

def main():
    """ä¸»æ¨ç†å‡½æ•°"""
    parser = argparse.ArgumentParser(description='COCOAttributeså±æ€§é¢„æµ‹æ¨ç†')
    parser.add_argument('--image_path', type=str, help='å•å¼ å›¾åƒè·¯å¾„')
    parser.add_argument('--image_dir', type=str, help='å›¾åƒç›®å½•è·¯å¾„ï¼ˆæ‰¹é‡æ¨ç†ï¼‰')
    parser.add_argument('--model_path', type=str, default='./checkpoints_coco/best_model.pth', help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_path', type=str, default=None, help='è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch_size', type=int, default=8, help='æ‰¹é‡æ¨ç†çš„æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--device', type=str, default='auto', help='è®¡ç®—è®¾å¤‡')
    
    args = parser.parse_args()
    
    if not args.image_path and not args.image_dir:
        print("é”™è¯¯: å¿…é¡»æŒ‡å®š --image_path æˆ– --image_dir")
        return False
    
    print("å¼€å§‹COCOAttributeså±æ€§é¢„æµ‹æ¨ç†...")
    
    # è®¾ç½®è®¾å¤‡
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    try:
        # åŠ è½½é…ç½®
        from config.base_config import get_config
        config = get_config('COCOAttributes')
        print(f"é…ç½®åŠ è½½æˆåŠŸ")
        
        # åŠ è½½æ¨¡å‹
        model = load_model(args.model_path, config, device)
        
        # è·å–ç±»åˆ«åç§°
        class_names = get_attribute_class_names()
        
        # å•å¼ å›¾åƒæ¨ç†
        if args.image_path:
            print(f"\nå•å¼ å›¾åƒæ¨ç†: {args.image_path}")
            
            if not os.path.exists(args.image_path):
                print(f"é”™è¯¯: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {args.image_path}")
                return False
            
            # é¢„å¤„ç†å›¾åƒ
            image_tensor = preprocess_image(args.image_path, config.image_size)
            print(f"å›¾åƒé¢„å¤„ç†å®Œæˆ: {image_tensor.shape}")
            
            # è¿›è¡Œé¢„æµ‹
            results = predict_attributes(model, image_tensor, config, device)
            formatted_results = format_results(results, class_names)
            
            # æ‰“å°ç»“æœ
            print(f"\nğŸ“Š é¢„æµ‹ç»“æœ (å›¾åƒ: {os.path.basename(args.image_path)}):")
            print("=" * 60)
            for attr_name, pred_info in formatted_results.items():
                print(f"{attr_name.upper()}:")
                print(f"  é¢„æµ‹ç±»åˆ«: {pred_info['predicted_class']}")
                print(f"  ç½®ä¿¡åº¦: {pred_info['confidence']}")
                print()
            
            # ä¿å­˜ç»“æœ
            if args.output_path:
                output_data = {
                    'image_path': args.image_path,
                    'predictions': formatted_results,
                    'raw_results': results
                }
                
                with open(args.output_path, 'w', encoding='utf-8') as f:
                    json.dump(output_data, f, indent=2, ensure_ascii=False)
                print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.output_path}")
        
        # æ‰¹é‡æ¨ç†
        elif args.image_dir:
            print(f"\næ‰¹é‡æ¨ç†: {args.image_dir}")
            
            if not os.path.exists(args.image_dir):
                print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {args.image_dir}")
                return False
            
            # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
            image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
            image_paths = []
            
            for ext in image_extensions:
                image_paths.extend(Path(args.image_dir).glob(f'*{ext}'))
                image_paths.extend(Path(args.image_dir).glob(f'*{ext.upper()}'))
            
            if not image_paths:
                print(f"é”™è¯¯: åœ¨ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {args.image_dir}")
                return False
            
            print(f"æ‰¾åˆ° {len(image_paths)} å¼ å›¾åƒ")
            
            # æ‰¹é‡æ¨ç†
            batch_results = batch_inference(model, image_paths, config, device, args.batch_size)
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_batch_results = []
            for result in batch_results:
                formatted_pred = format_results(result['predictions'], class_names)
                formatted_batch_results.append({
                    'image_path': result['image_path'],
                    'predictions': formatted_pred
                })
            
            # æ‰“å°éƒ¨åˆ†ç»“æœ
            print(f"\nğŸ“Š æ‰¹é‡æ¨ç†ç»“æœ (æ˜¾ç¤ºå‰5ä¸ª):")
            print("=" * 60)
            for i, result in enumerate(formatted_batch_results[:5]):
                print(f"\nå›¾åƒ {i+1}: {os.path.basename(result['image_path'])}")
                for attr_name, pred_info in result['predictions'].items():
                    print(f"  {attr_name}: {pred_info['predicted_class']} ({pred_info['confidence']})")
            
            if len(formatted_batch_results) > 5:
                print(f"\n... è¿˜æœ‰ {len(formatted_batch_results) - 5} ä¸ªç»“æœ")
            
            # ä¿å­˜ç»“æœ
            if args.output_path:
                output_data = {
                    'total_images': len(formatted_batch_results),
                    'results': formatted_batch_results
                }
                
                with open(args.output_path, 'w', encoding='utf-8') as f:
                    json.dump(output_data, f, indent=2, ensure_ascii=False)
                print(f"\næ‰¹é‡ç»“æœå·²ä¿å­˜åˆ°: {args.output_path}")
        
        print("\nâœ… æ¨ç†å®Œæˆ!")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ COCOAttributesæ¨ç†è„šæœ¬è¿è¡ŒæˆåŠŸ!")
    else:
        print("\nğŸ’¥ COCOAttributesæ¨ç†è„šæœ¬è¿è¡Œå¤±è´¥!")
